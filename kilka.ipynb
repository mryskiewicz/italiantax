{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T15:15:44.964178Z",
     "start_time": "2025-03-14T15:15:44.961355Z"
    }
   },
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:02:32.201305Z",
     "start_time": "2025-03-14T15:02:32.198875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_PATH = \"laws\"\n",
    "OUTPUT_PATH = \"laws_clean\"\n",
    "TAG_PATH = \"laws_tagged\""
   ],
   "id": "77b606bdf84b313d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b9239317304e0391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:53:57.348470Z",
     "start_time": "2025-03-14T14:53:57.345504Z"
    }
   },
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"AGGIORNAMENTO \\(\\d+\\).*?(?=Art\\.)\", \"\", text, flags = re.DOTALL)\n",
    "    return cleaned_text"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:53:59.951935Z",
     "start_time": "2025-03-14T14:53:59.916770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file in os.listdir(INPUT_PATH):\n",
    "    with open(os.path.join(INPUT_PATH, file), \"r\") as f:\n",
    "        text = f.read()\n",
    "    cleaned_text = clean_text(text)\n",
    "    with open(os.path.join(OUTPUT_PATH, file), \"w\") as f:\n",
    "        f.write(cleaned_text)"
   ],
   "id": "cc493e959cd36a56",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:58:10.137216Z",
     "start_time": "2025-03-14T14:58:07.769614Z"
    }
   },
   "cell_type": "code",
   "source": "import spacy",
   "id": "1a6ee43e7abc23ca",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:59:11.351728Z",
     "start_time": "2025-03-14T14:59:10.865057Z"
    }
   },
   "cell_type": "code",
   "source": "nlp = spacy.load(\"it_core_news_sm\")",
   "id": "c76d8600c9fca13f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:23:25.634238Z",
     "start_time": "2025-03-14T15:23:25.630267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tag_text(text):\n",
    "    doc = nlp(text)\n",
    "    tagged_sentences = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tagged_tokens = [\n",
    "            f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.tag_}\\t{token.dep_}\" for token in sent\n",
    "        ]\n",
    "        tagged_sentences.append(\"\\n\".join(tagged_tokens))\n",
    "    return \"\\n\\n\".join(tagged_sentences)"
   ],
   "id": "a2d30eb2d5ccdf52",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:25:10.572704Z",
     "start_time": "2025-03-14T15:23:26.389912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file in os.listdir(INPUT_PATH):\n",
    "    with open(os.path.join(OUTPUT_PATH, file), \"r\") as f:\n",
    "        text = f.read()\n",
    "    tagged_text = tag_text(text)\n",
    "    with open(os.path.join(TAG_PATH, file), \"w\") as f:\n",
    "        f.write(tagged_text)"
   ],
   "id": "779834c68f506e1c",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:25:35.194551Z",
     "start_time": "2025-03-14T15:25:35.044012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "\n",
    "for file in os.listdir(TAG_PATH):\n",
    "    df = pd.read_csv(os.path.join(TAG_PATH, file), sep=\"\\t\", header=None, names = ['token', 'lemma', 'pos', 'tag', 'dep'], keep_default_na=False)\n",
    "    pos_counts = df['pos'].value_counts().to_dict()\n",
    "    pos_counts['file_name'] = file\n",
    "    data.append(pos_counts)\n",
    "\n",
    "df_summary = pd.DataFrame(data).fillna(0)\n",
    "output_path = \"laws_summary.csv\"\n",
    "df_summary.to_csv(output_path, index=False)"
   ],
   "id": "3ebf030a0879d3df",
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 95050, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(TAG_PATH):\n\u001B[0;32m----> 4\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTAG_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtoken\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlemma\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtag\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdep\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_default_na\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     pos_counts \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpos\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts()\u001B[38;5;241m.\u001B[39mto_dict()\n\u001B[1;32m      6\u001B[0m     pos_counts[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfile_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m file\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32mparsers.pyx:838\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:905\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:874\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:891\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:2061\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mParserError\u001B[0m: Error tokenizing data. C error: Expected 5 fields in line 95050, saw 7\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:25:41.996154Z",
     "start_time": "2025-03-14T15:25:41.758315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Ścieżka do katalogu z plikami\n",
    "folder_path = \"laws_tagged\"  # <-- Podmień na właściwą ścieżkę\n",
    "\n",
    "# Licznik dla liczby pól w wierszach\n",
    "field_counts = Counter()\n",
    "\n",
    "# Sprawdzanie liczby pól w każdej linii w plikach\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):  # Tylko pliki tekstowe\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                num_fields = line.strip().count(\"\\t\") + 1  # Liczymy kolumny (ilość tabulatorów + 1)\n",
    "                field_counts[num_fields] += 1  # Zliczamy różne przypadki\n",
    "\n",
    "# Tworzenie DataFrame dla analizy\n",
    "df_fields = pd.DataFrame(field_counts.items(), columns=[\"num_fields\", \"num_lines\"]).sort_values(by=\"num_fields\")\n",
    "\n",
    "print(df_fields)"
   ],
   "id": "82f2970c5ba7b98e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_fields  num_lines\n",
      "1           1      30413\n",
      "2           3       8078\n",
      "0           5     404580\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:26:10.102117Z",
     "start_time": "2025-03-14T15:26:09.697924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "for filename in os.listdir(TAG_PATH):\n",
    "    file_path = os.path.join(TAG_PATH, filename)\n",
    "    rows = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            if len(fields) == 5:\n",
    "                token, lemma, pos, tag, dep = fields\n",
    "                rows.append(pos)\n",
    "    df = pd.DataFrame(rows, columns = ['pos'])\n",
    "    pos_counts = df['pos'].value_counts().to_dict()\n",
    "    pos_counts['file_name'] = filename\n",
    "    data.append(pos_counts)"
   ],
   "id": "9176bbc0e3081b55",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:26:34.427935Z",
     "start_time": "2025-03-14T15:26:34.422362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_summary = pd.DataFrame(data).fillna(0)\n",
    "output_path = \"laws_summary_pos.csv\"\n",
    "df_summary.to_csv(output_path, index = False)"
   ],
   "id": "9c663b321c355ebb",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:34:08.146610Z",
     "start_time": "2025-03-14T15:34:08.136195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df_summary.head(10)"
   ],
   "id": "e2b45ccd6cc4b83e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    NOUN    ADP  PUNCT    NUM   ADJ   DET  VERB  CCONJ  PRON  PROPN   AUX  \\\n",
       "0   5821   4607   2963   1871  1797  1321  1122    684   532    395   366   \n",
       "1  24002  17780  12676   5491  7195  5359  5308   3741  2408   2073  1569   \n",
       "2   2191   1599   1156    367   745   576   506    286   178     56   183   \n",
       "3  32981  27952  15800  11592  8933  6874  5851   3622  2396   1226  1939   \n",
       "4  24716  20577  11917   8498  6562  4991  4146   2541  1659   1031  1441   \n",
       "5  19842  15812   9569   4457  6202  4572  4525   2749  2252    854  1249   \n",
       "\n",
       "    ADV  SCONJ    X   SYM     file_name  nominality  nominality_wider  \n",
       "0   345     95   57   5.0  446_1997.txt        5.19              7.00  \n",
       "1  1662    540  186   4.0  633_1972.txt        4.52              5.99  \n",
       "2   214     38   23   0.0  212_2000.txt        4.33              5.13  \n",
       "3  1351    165  220   2.0  197_2022.txt        5.64              7.33  \n",
       "4   876    154  127  16.0  213_2023.txt        5.96              7.60  \n",
       "5  1568    419  261   0.0  917_1986.txt        4.38              5.82  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>VERB</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADV</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>X</th>\n",
       "      <th>SYM</th>\n",
       "      <th>file_name</th>\n",
       "      <th>nominality</th>\n",
       "      <th>nominality_wider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5821</td>\n",
       "      <td>4607</td>\n",
       "      <td>2963</td>\n",
       "      <td>1871</td>\n",
       "      <td>1797</td>\n",
       "      <td>1321</td>\n",
       "      <td>1122</td>\n",
       "      <td>684</td>\n",
       "      <td>532</td>\n",
       "      <td>395</td>\n",
       "      <td>366</td>\n",
       "      <td>345</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>446_1997.txt</td>\n",
       "      <td>5.19</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24002</td>\n",
       "      <td>17780</td>\n",
       "      <td>12676</td>\n",
       "      <td>5491</td>\n",
       "      <td>7195</td>\n",
       "      <td>5359</td>\n",
       "      <td>5308</td>\n",
       "      <td>3741</td>\n",
       "      <td>2408</td>\n",
       "      <td>2073</td>\n",
       "      <td>1569</td>\n",
       "      <td>1662</td>\n",
       "      <td>540</td>\n",
       "      <td>186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>633_1972.txt</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2191</td>\n",
       "      <td>1599</td>\n",
       "      <td>1156</td>\n",
       "      <td>367</td>\n",
       "      <td>745</td>\n",
       "      <td>576</td>\n",
       "      <td>506</td>\n",
       "      <td>286</td>\n",
       "      <td>178</td>\n",
       "      <td>56</td>\n",
       "      <td>183</td>\n",
       "      <td>214</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212_2000.txt</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32981</td>\n",
       "      <td>27952</td>\n",
       "      <td>15800</td>\n",
       "      <td>11592</td>\n",
       "      <td>8933</td>\n",
       "      <td>6874</td>\n",
       "      <td>5851</td>\n",
       "      <td>3622</td>\n",
       "      <td>2396</td>\n",
       "      <td>1226</td>\n",
       "      <td>1939</td>\n",
       "      <td>1351</td>\n",
       "      <td>165</td>\n",
       "      <td>220</td>\n",
       "      <td>2.0</td>\n",
       "      <td>197_2022.txt</td>\n",
       "      <td>5.64</td>\n",
       "      <td>7.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24716</td>\n",
       "      <td>20577</td>\n",
       "      <td>11917</td>\n",
       "      <td>8498</td>\n",
       "      <td>6562</td>\n",
       "      <td>4991</td>\n",
       "      <td>4146</td>\n",
       "      <td>2541</td>\n",
       "      <td>1659</td>\n",
       "      <td>1031</td>\n",
       "      <td>1441</td>\n",
       "      <td>876</td>\n",
       "      <td>154</td>\n",
       "      <td>127</td>\n",
       "      <td>16.0</td>\n",
       "      <td>213_2023.txt</td>\n",
       "      <td>5.96</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19842</td>\n",
       "      <td>15812</td>\n",
       "      <td>9569</td>\n",
       "      <td>4457</td>\n",
       "      <td>6202</td>\n",
       "      <td>4572</td>\n",
       "      <td>4525</td>\n",
       "      <td>2749</td>\n",
       "      <td>2252</td>\n",
       "      <td>854</td>\n",
       "      <td>1249</td>\n",
       "      <td>1568</td>\n",
       "      <td>419</td>\n",
       "      <td>261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917_1986.txt</td>\n",
       "      <td>4.38</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:33:51.770915Z",
     "start_time": "2025-03-14T15:33:51.766175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_summary = df_summary.assign(\n",
    "    nominality = lambda x: round(x.NOUN / x.VERB, 2),\n",
    "    nominality_wider = lambda x: round((x.NOUN + x.PROPN + x.PRON + x.ADJ + x.NUM) / (x.VERB + x.AUX), 2)\n",
    ")"
   ],
   "id": "31e2e66537c923f0",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:50:08.732479Z",
     "start_time": "2025-03-14T15:50:08.670645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "\n",
    "for filename in os.listdir(OUTPUT_PATH):\n",
    "    file_path = os.path.join(OUTPUT_PATH, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    articles = re.split(r\"\\bArt\\.\\s\", text)[1:]\n",
    "    lengths = [len(article.split()) for article in articles]\n",
    "    avg_length = round(sum(lengths) / len(lengths), 2)\n",
    "    data.append({\"file_name\": filename, \"avg_length\": avg_length})\n",
    "\n",
    "df_avg_length_abs = pd.DataFrame(data)"
   ],
   "id": "f0c0ebf981a98396",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:50:12.670088Z",
     "start_time": "2025-03-14T15:50:12.664800Z"
    }
   },
   "cell_type": "code",
   "source": "df_avg_length_abs.head(10)",
   "id": "fc054f3029f74853",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      file_name  avg_length\n",
       "0  446_1997.txt      247.07\n",
       "1  633_1972.txt      433.87\n",
       "2  212_2000.txt      182.08\n",
       "3  197_2022.txt     3640.32\n",
       "4  213_2023.txt     1823.41\n",
       "5  917_1986.txt      400.65"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>avg_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446_1997.txt</td>\n",
       "      <td>247.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633_1972.txt</td>\n",
       "      <td>433.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212_2000.txt</td>\n",
       "      <td>182.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197_2022.txt</td>\n",
       "      <td>3640.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213_2023.txt</td>\n",
       "      <td>1823.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>917_1986.txt</td>\n",
       "      <td>400.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:51:58.536038Z",
     "start_time": "2025-03-14T15:51:58.521144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_merged = (\n",
    "    df_avg_length_rel\n",
    "    .merge(df_avg_length_abs, on=\"file_name\", suffixes=(\"_rel\", \"_abs\"))\n",
    "    .merge(df_summary, on=\"file_name\")\n",
    ")\n",
    "\n",
    "columns_order = [\"file_name\"] + [col for col in df_merged.columns if col != \"file_name\"]\n",
    "df_merged = df_merged[columns_order]\n",
    "\n",
    "df_merged.head()"
   ],
   "id": "e93b927334f2eade",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      file_name  avg_length_rel  avg_length_abs   NOUN    ADP  PUNCT    NUM  \\\n",
       "0  446_1997.txt           63.19          247.07   5821   4607   2963   1871   \n",
       "1  633_1972.txt          148.62          433.87  24002  17780  12676   5491   \n",
       "2  212_2000.txt           43.27          182.08   2191   1599   1156    367   \n",
       "3  197_2022.txt           99.65         3640.32  32981  27952  15800  11592   \n",
       "4  213_2023.txt           98.34         1823.41  24716  20577  11917   8498   \n",
       "\n",
       "    ADJ   DET  VERB  CCONJ  PRON  PROPN   AUX   ADV  SCONJ    X   SYM  \\\n",
       "0  1797  1321  1122    684   532    395   366   345     95   57   5.0   \n",
       "1  7195  5359  5308   3741  2408   2073  1569  1662    540  186   4.0   \n",
       "2   745   576   506    286   178     56   183   214     38   23   0.0   \n",
       "3  8933  6874  5851   3622  2396   1226  1939  1351    165  220   2.0   \n",
       "4  6562  4991  4146   2541  1659   1031  1441   876    154  127  16.0   \n",
       "\n",
       "   nominality  nominality_wider  \n",
       "0        5.19              7.00  \n",
       "1        4.52              5.99  \n",
       "2        4.33              5.13  \n",
       "3        5.64              7.33  \n",
       "4        5.96              7.60  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>avg_length_rel</th>\n",
       "      <th>avg_length_abs</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>VERB</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADV</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>X</th>\n",
       "      <th>SYM</th>\n",
       "      <th>nominality</th>\n",
       "      <th>nominality_wider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446_1997.txt</td>\n",
       "      <td>63.19</td>\n",
       "      <td>247.07</td>\n",
       "      <td>5821</td>\n",
       "      <td>4607</td>\n",
       "      <td>2963</td>\n",
       "      <td>1871</td>\n",
       "      <td>1797</td>\n",
       "      <td>1321</td>\n",
       "      <td>1122</td>\n",
       "      <td>684</td>\n",
       "      <td>532</td>\n",
       "      <td>395</td>\n",
       "      <td>366</td>\n",
       "      <td>345</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633_1972.txt</td>\n",
       "      <td>148.62</td>\n",
       "      <td>433.87</td>\n",
       "      <td>24002</td>\n",
       "      <td>17780</td>\n",
       "      <td>12676</td>\n",
       "      <td>5491</td>\n",
       "      <td>7195</td>\n",
       "      <td>5359</td>\n",
       "      <td>5308</td>\n",
       "      <td>3741</td>\n",
       "      <td>2408</td>\n",
       "      <td>2073</td>\n",
       "      <td>1569</td>\n",
       "      <td>1662</td>\n",
       "      <td>540</td>\n",
       "      <td>186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212_2000.txt</td>\n",
       "      <td>43.27</td>\n",
       "      <td>182.08</td>\n",
       "      <td>2191</td>\n",
       "      <td>1599</td>\n",
       "      <td>1156</td>\n",
       "      <td>367</td>\n",
       "      <td>745</td>\n",
       "      <td>576</td>\n",
       "      <td>506</td>\n",
       "      <td>286</td>\n",
       "      <td>178</td>\n",
       "      <td>56</td>\n",
       "      <td>183</td>\n",
       "      <td>214</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197_2022.txt</td>\n",
       "      <td>99.65</td>\n",
       "      <td>3640.32</td>\n",
       "      <td>32981</td>\n",
       "      <td>27952</td>\n",
       "      <td>15800</td>\n",
       "      <td>11592</td>\n",
       "      <td>8933</td>\n",
       "      <td>6874</td>\n",
       "      <td>5851</td>\n",
       "      <td>3622</td>\n",
       "      <td>2396</td>\n",
       "      <td>1226</td>\n",
       "      <td>1939</td>\n",
       "      <td>1351</td>\n",
       "      <td>165</td>\n",
       "      <td>220</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>7.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213_2023.txt</td>\n",
       "      <td>98.34</td>\n",
       "      <td>1823.41</td>\n",
       "      <td>24716</td>\n",
       "      <td>20577</td>\n",
       "      <td>11917</td>\n",
       "      <td>8498</td>\n",
       "      <td>6562</td>\n",
       "      <td>4991</td>\n",
       "      <td>4146</td>\n",
       "      <td>2541</td>\n",
       "      <td>1659</td>\n",
       "      <td>1031</td>\n",
       "      <td>1441</td>\n",
       "      <td>876</td>\n",
       "      <td>154</td>\n",
       "      <td>127</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:50:21.519159Z",
     "start_time": "2025-03-14T15:50:21.452157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "\n",
    "for filename in os.listdir(OUTPUT_PATH):\n",
    "    file_path = os.path.join(OUTPUT_PATH, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    articles = re.split(r\"\\bArt\\.\\s\", text)[1:]\n",
    "    lengths = []\n",
    "\n",
    "    for article in articles:\n",
    "        sections = re.split(r\"\\n\\s*\\d+\\.\\s\", article)\n",
    "        if len(sections) == 1:\n",
    "            lengths.append(len(article.split()))\n",
    "        else:\n",
    "            for section in sections:\n",
    "                section_length = len(section.split())\n",
    "                if section_length > 0:\n",
    "                    lengths.append(section_length)\n",
    "\n",
    "    avg_length = round(sum(lengths) / len(lengths), 2)\n",
    "    data.append({\"file_name\": filename, \"avg_length\": avg_length})\n",
    "\n",
    "df_avg_length_rel = pd.DataFrame(data)"
   ],
   "id": "e5a7ad62c6b126f8",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:50:23.202111Z",
     "start_time": "2025-03-14T15:50:23.196762Z"
    }
   },
   "cell_type": "code",
   "source": "df_avg_length_rel.head(10)",
   "id": "ce7eb2997d3b70a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      file_name  avg_length\n",
       "0  446_1997.txt       63.19\n",
       "1  633_1972.txt      148.62\n",
       "2  212_2000.txt       43.27\n",
       "3  197_2022.txt       99.65\n",
       "4  213_2023.txt       98.34\n",
       "5  917_1986.txt       97.97"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>avg_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446_1997.txt</td>\n",
       "      <td>63.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633_1972.txt</td>\n",
       "      <td>148.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212_2000.txt</td>\n",
       "      <td>43.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197_2022.txt</td>\n",
       "      <td>99.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213_2023.txt</td>\n",
       "      <td>98.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>917_1986.txt</td>\n",
       "      <td>97.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T15:55:22.575664Z",
     "start_time": "2025-03-14T15:55:22.568630Z"
    }
   },
   "cell_type": "code",
   "source": "df_merged[['file_name', 'avg_length_abs', 'avg_length_rel', 'nominality', 'nominality_wider']].head(10)\n",
   "id": "ca6628c9f731cda0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      file_name  avg_length_abs  avg_length_rel  nominality  nominality_wider\n",
       "0  446_1997.txt          247.07           63.19        5.19              7.00\n",
       "1  633_1972.txt          433.87          148.62        4.52              5.99\n",
       "2  212_2000.txt          182.08           43.27        4.33              5.13\n",
       "3  197_2022.txt         3640.32           99.65        5.64              7.33\n",
       "4  213_2023.txt         1823.41           98.34        5.96              7.60\n",
       "5  917_1986.txt          400.65           97.97        4.38              5.82"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>avg_length_abs</th>\n",
       "      <th>avg_length_rel</th>\n",
       "      <th>nominality</th>\n",
       "      <th>nominality_wider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446_1997.txt</td>\n",
       "      <td>247.07</td>\n",
       "      <td>63.19</td>\n",
       "      <td>5.19</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633_1972.txt</td>\n",
       "      <td>433.87</td>\n",
       "      <td>148.62</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212_2000.txt</td>\n",
       "      <td>182.08</td>\n",
       "      <td>43.27</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197_2022.txt</td>\n",
       "      <td>3640.32</td>\n",
       "      <td>99.65</td>\n",
       "      <td>5.64</td>\n",
       "      <td>7.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213_2023.txt</td>\n",
       "      <td>1823.41</td>\n",
       "      <td>98.34</td>\n",
       "      <td>5.96</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>917_1986.txt</td>\n",
       "      <td>400.65</td>\n",
       "      <td>97.97</td>\n",
       "      <td>4.38</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "330dc9567ff7e7cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
